{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_minibatch(x, y):\n",
    "    assert x.size(0)== y.size(0)\n",
    "    indices = torch.randperm(x.size(0))\n",
    "    return x[indices], y[indices]\n",
    "\n",
    "CUTMIX_ALPHA = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 224, h = 224\n",
    "epoch = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "epochs = 200\n",
    "\n",
    "for idx,(train_index, valid_index) in enumerate(kfold.split(df_train['img_file'],df_train['class'])):\n",
    "    print(\"fold\", idx)\n",
    "    \n",
    "    x_train_ = df_train.iloc[train_index,:]\n",
    "    x_valid_ = df_train.iloc[valid_index,:]    \n",
    "    y_true = x_valid_['class'].values \n",
    "    \n",
    "    train_dataset =  KaggleDataset(x_train_, mode = 'train', path = TRAIN_CROPPED_PATH,\n",
    "                              transforms = data_transforms['train']\n",
    "                              )\n",
    "    valid_dataset =  KaggleDataset(x_valid_, mode = 'valid', path = TRAIN_CROPPED_PATH,\n",
    "                                  transforms = data_transforms['valid']\n",
    "                                  )\n",
    "    # data loader\n",
    "    train_loader = DataLoader(train_dataset, batch_size = BATCH , shuffle =True)#, num_workers =3,pin_memory=True )\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size = BATCH , shuffle =False)#, num_workers =3 )\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=15, verbose=True,number=idx)\n",
    "    model = models.resnet101(pretrained=True)\n",
    "    model.fc =nn.Linear(2048, num_classes)\n",
    "    model.to(device)#.cuda()\n",
    "    learning_rate = 0.001\n",
    "    criterion = torch.nn.CrossEntropyLoss()#.to(device) # Softmax is internel computed\n",
    "    #criterion = arcloss(features)\n",
    "    #criterion = ArcMarginProduct(196, 512, s=30, m=0.5, easy_margin=True)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)\n",
    "    scheduler = ReduceLROnPlateau(optimizer,'min',factor=0.7, patience=3, min_lr=1e-10,verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(epoch)\n",
    "        model.train() # set the model to train mode(dropout=True)\n",
    "\n",
    "        train_loss = 0.\n",
    "        valid_loss = 0.\n",
    "        valid_preds = np.zeros((len(valid_dataset), num_classes))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        for i, (inputs, targets) in enumerate(train_loader):\n",
    "\n",
    "            inputs, targets = inputs.to(device), targets.to(device)                       \n",
    "            \n",
    "            \n",
    "            #-------------------------------------------------------\n",
    "            # CUTMIX\n",
    "            #h ttps://www.kaggle.com/kaushal2896/cifar-10-simple-cnn-with-cutmix-using-pytorch\n",
    "                        \n",
    "            cutmix_decision = np.random.rand()\n",
    "            if cutmix_decision > 0.50:\n",
    "                # Cutmix: https://arxiv.org/pdf/1905.04899.pdf\n",
    "                x_train_shuffled, y_train_shuffled = shuffle_minibatch(inputs, targets)\n",
    "                lam = np.random.beta(CUTMIX_ALPHA, CUTMIX_ALPHA)\n",
    "                cut_rat = np.sqrt(1. - lam)\n",
    "                \n",
    "                cut_w = np.int(W * cut_rat)\n",
    "                cut_h = np.int(H * cut_rat)\n",
    "\n",
    "                # uniform\n",
    "                cx = np.random.randint(W)\n",
    "                cy = np.random.randint(H)\n",
    "\n",
    "\n",
    "                bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "                bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "                bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "                bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "                inputs[:, :, bbx1:bbx2, bby1:bby2] = x_train_shuffled[:, :, bbx1:bbx2, bby1:bby2]\n",
    "                lam = 1 - (bbx2 - bbx1) * (bby2 - bby1) / (W * H)\n",
    "\n",
    "            # Forward pass\n",
    "            y_preds = model(inputs)\n",
    "\n",
    "            # Calculate loss\n",
    "            '''\n",
    "            if cutmix_decision > 0.50:\n",
    "                loss = criterion(y_preds, targets) * lam + criterion(y_preds, y_train_shuffled) * (1. - lam)\n",
    "            else:\n",
    "                loss = criterion(y_preds, targets)\n",
    "            if i+1 == total_steps:\n",
    "                loss_list.append(loss)\n",
    "\n",
    "            '''\n",
    "\n",
    "            \n",
    "            \n",
    "            # CUT MIX\n",
    "            #----------------------------------------------------------\n",
    "            \n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            train_loss += loss.item() / len(train_loader)\n",
    "\n",
    "        # validation\n",
    "        model.eval() # 평가모드로 전환 dropoput False\n",
    "        with torch.no_grad():\n",
    "            for i, (inputs, targets) in enumerate(valid_loader):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                valid_loss += loss.item() / len(valid_loader)\n",
    "                valid_preds[i * BATCH: (i+1) * BATCH] = outputs.cpu().numpy()\n",
    "            y_pred = np.argmax(valid_preds, axis=1)\n",
    "            val_score = f1_score(y_true, y_pred, average='micro')  \n",
    "\n",
    "        print(\"Epoch {} , train_loss {:.4f}, valid_loss {:.4f}, val_f1_score {:.4f}\".format(epoch, train_loss, valid_loss, val_score))\n",
    "\n",
    "        scheduler.step(valid_loss)\n",
    "\n",
    "        early_stopping(valid_loss, model)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "    del model\n",
    "    gc.collect()\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
